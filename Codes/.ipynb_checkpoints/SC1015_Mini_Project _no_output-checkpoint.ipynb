{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "\n",
    "* ## [Import Contents](#importContents)\n",
    "    * [Importing Modules](#importingModules)\n",
    "    * [Spotify API](#spotifyAPI)\n",
    "    * [Importing Dataset](#importingDataset)\n",
    "    * [Label References](#labelReferences)\n",
    "\n",
    "* ## [Exploratory Data Analysis](#eda)\n",
    "    * ### [Basic Cleaning](#basicCleaning)\n",
    "        * [Handling NaN Values](#NaN)\n",
    "        * [Handling Duplicates](#duplicates)\n",
    "    * ### [Basic Exploration](#basicEx)\n",
    "        * [Numerical Data](#numerical1)\n",
    "        * [Categorical Data](#categorical1)\n",
    "    * ### [Advanced Cleaning](#advancedCleaning)\n",
    "        * [Numerical Data](#numerical2)\n",
    "        * [Categorical Data](#categorical2)\n",
    "    * ### [Advanced Exploration](#advancedEx)\n",
    "        * [Graph Plots](#graphs)\n",
    "        * [Feature Selection](#feature)\n",
    "        * [One Hot Encoding](#ohe)\n",
    "        \n",
    "* ## [Machine Learning](#ml)\n",
    "    * ### [Train-Test Split](#traintest)\n",
    "    * ### [Decision Tree](#dectree)\n",
    "    * ### [Random Forest](#randomForest)\n",
    "    * ### [K Nearest Neighbors](#knn)\n",
    "    * ### [Logistic Regression](#logreg)\n",
    "    * ### [Gradient Boosting](#gradientBoosting)\n",
    "       \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Import Contents** <a class=\"anchor\" id=\"importContents\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p4FQxHtbYYY5"
   },
   "source": [
    "## **Importing Modules** <a class=\"anchor\" id=\"importingModules\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SzZXb9Ylh8WU",
    "outputId": "5f40e1e9-d426-4c5f-aea6-325af59805e5"
   },
   "outputs": [],
   "source": [
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OXvbSYxColPk"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "from time import sleep\n",
    "ROOT = \"/content\"\n",
    "from tqdm import tqdm\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4aYUC4slYgZR"
   },
   "source": [
    "## **Spotify API** <a class=\"anchor\" id=\"spotifyAPI\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SaF3aTlD_tKu"
   },
   "source": [
    "We first obtain our raw data from the spotify million playlist dataset:\n",
    "https://www.aicrowd.com/challenges/spotify-million-playlist-dataset-challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IlKcB-tO_3bN"
   },
   "source": [
    "The raw dataset provides the basic details of tracks on spotify, such as name, artist and identification (URI). We extract a few slices from the entire dataset (~60,000 songs) and upload them to google colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tizsSoN6ZqUM"
   },
   "outputs": [],
   "source": [
    "!pip install spotipy==2.16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q0O6x3Mlycmv"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O6VvkhTvyyNa"
   },
   "outputs": [],
   "source": [
    "!unzip mpd.slice2.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I4c6QJckAeUX"
   },
   "source": [
    "Next, we import the spotipy library to interect with the spotify API directly from google colab. This allows us to send the spotify API requests, and extract the song-specific details for our machine learning algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9H80O0kSX36D"
   },
   "outputs": [],
   "source": [
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "client_credentials_manager = SpotifyClientCredentials(client_id=\"5fa1b1f372a54022be85dbdaaa792649\", client_secret=\"84f297f748304b5c9a616c85b0139fb9\")\n",
    "sp = spotipy.Spotify(client_credentials_manager = client_credentials_manager)\n",
    "def get_URI(link):\n",
    "  return link.split(\"/\")[-1].split(\"?\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kyw8jbBl2lu0"
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f4PpqC7BZlWZ"
   },
   "outputs": [],
   "source": [
    "for i in range(1,7):\n",
    "  file = \"mpd.slice.{}.json\".format(i)\n",
    "  print(\"Processing \"+ file)\n",
    "  with open(file) as train_file:\n",
    "      dictionary = json.load(train_file)\n",
    "      \n",
    "  playlists = [x[\"tracks\"] for x in dictionary[\"playlists\"]]\n",
    "  tracks = [x[\"track_uri\"] for playlist in playlists for x in playlist]\n",
    "\n",
    "\n",
    "  for i in tqdm(range(0,len(tracks)-50, 50)):\n",
    "    part = tracks[i:i+50]\n",
    "    try:\n",
    "      part_data = sp.audio_features(part)\n",
    "      part_info = sp.tracks(part)['tracks']\n",
    "\n",
    "      part_artists_info = sp.artists([artist['artists'][0]['id'] for artist in part_info])[\"artists\"]\n",
    "      part_artist = [artist[\"name\"] for artist in part_artists_info]\n",
    "      part_genre = [\"/\".join(artist[\"genres\"]) for artist in part_artists_info]\n",
    "\n",
    "      part_df = pd.concat([pd.DataFrame(part_data).drop([\"id\",\"uri\",\"track_href\",\"analysis_url\"],axis=1), pd.DataFrame(part_info)[[\"name\",\"popularity\"]]],axis=1)\n",
    "      part_df[\"artist\"] = part_artist\n",
    "      part_df[\"genre\"] = part_genre\n",
    "\n",
    "      df = pd.concat([df, part_df])\n",
    "\n",
    "    except:\n",
    "      pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DupTrQHPA26z"
   },
   "outputs": [],
   "source": [
    "df.to_csv(\"spotify_dataset.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nEIVx1dKEBrQ"
   },
   "source": [
    "## **Importing Dataset** <a class=\"anchor\" id=\"importingDataset\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RYOP8_oFBFty"
   },
   "source": [
    "Here, we upload our extracted data and display it to get a general understanding of it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 111,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "id": "07TJuhAFbRRU",
    "outputId": "986a6d02-f2ac-4107-efe5-48178bf63409"
   },
   "outputs": [],
   "source": [
    "# Upload \"spotify_dataset.csv\"\n",
    "from google.colab import files\n",
    "files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 565
    },
    "id": "5F_RXzv6Bs4U",
    "outputId": "fe238953-9669-410e-863d-cb81aa128913"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"spotify_dataset.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LQho79M_aZ8v"
   },
   "outputs": [],
   "source": [
    "# Drop irrelevant columns\n",
    "df = df.drop([\"Unnamed: 0\",'type','time_signature'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mwxuwwCbmXjP",
    "outputId": "4d7e09f2-7682-4902-8fe9-33fbe23c69fe"
   },
   "outputs": [],
   "source": [
    "df.info()\n",
    "print(\"There are {} unique titles, {} unique artists, and {} unique genres\".format(len(df.name.unique()),\n",
    "                                                                                   len(df.artist.unique()), \n",
    "                                                                                   len(df.genre.unique())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YRj6jCbwbvvh"
   },
   "source": [
    "## **Label References**  <a class=\"anchor\" id=\"labelReferences\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xjBjjINInSU1"
   },
   "source": [
    "\n",
    "title - name of the song\n",
    "\n",
    "artist - artist of the song\n",
    "\n",
    "genre - the genre of the track\n",
    "\n",
    "year - the release year of the recording. (may be unreliable due to re-releases and reuploads)\n",
    "\n",
    "bpm (beats per minute) - The tempo of the song.\n",
    "\n",
    "energy - The energy of a song - the higher the value, the more energtic\n",
    "\n",
    "dance - The higher the value, the easier it is to dance to\n",
    "\n",
    "volume (dB) - The higher the value, the louder the song\n",
    "\n",
    "live - The higher the value, the more likely the song is a live recording.\n",
    "\n",
    "valence - The higher the value, the more positive mood for the song.\n",
    "\n",
    "length - The duration of the song.\n",
    "\n",
    "acous (acoustics) - The higher the value the more acoustic the song is.\n",
    "\n",
    "speech (speechiness) - The higher the value the more spoken word the song \n",
    "\n",
    "pop (popularity) - The higher the value the more popular the song is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Exploratory Data Analysis** <a class=\"anchor\" id=\"eda\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gHvdoW7pbABh"
   },
   "source": [
    "# **Basic Cleaning** <a class=\"anchor\" id=\"basicCleaning\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rj4BEU1dBcBK"
   },
   "source": [
    "We proceed to do basic cleaning of the data such as handling NaN values and duplicates. This ensures that our models can be trained without skewed data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3KR9B5aGcBaR"
   },
   "source": [
    "## **Handling NaN values**  <a class=\"anchor\" id=\"NaN\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "id": "o0JH6sR0a_MZ",
    "outputId": "6cb6c146-f90f-4b1f-d120-62a1a3873c6e"
   },
   "outputs": [],
   "source": [
    "# Check for NaN values in the dataset\n",
    "df[df.isna().any(axis=1)].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hZmndvYTbZyx"
   },
   "source": [
    "Observation: Looks like most of the NaN comes from the genre column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 162
    },
    "id": "GP39U2tIOx9f",
    "outputId": "98ee0636-f29b-484b-f9d1-4bca82f6084d"
   },
   "outputs": [],
   "source": [
    "# Check for NaN that isn't under genre\n",
    "df[df.drop(\"genre\",axis=1).isna().any(axis=1)].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 887
    },
    "id": "Bbz-Rx1hcLaY",
    "outputId": "0a6b1ac4-fa49-481b-af9b-9d53c083c836"
   },
   "outputs": [],
   "source": [
    "# Remove NaN rows (excluding those in genre)\n",
    "df = df.dropna(how='any', subset=['danceability',\t'energy',\t'key', 'loudness',\t'mode',\t'speechiness',\t'acousticness',\t'instrumentalness',\t'liveness',\t'valence',\t'tempo',\t'duration_ms',\t'name',\t'popularity',\t'artist'])\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5A3k96AvRbbC"
   },
   "source": [
    "Observation: Only one row with NaN values (not from genre column)\n",
    "\n",
    "Before removal = 63032 rows\\\n",
    "After removal = 63031 rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9LdeNp3icSz5"
   },
   "source": [
    "## **Handling duplicates** <a class=\"anchor\" id=\"duplicates\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 765
    },
    "id": "5dZxeGBlwZiB",
    "outputId": "a86a0281-4d49-4d9a-8c44-b03eb7e8a632"
   },
   "outputs": [],
   "source": [
    "# sort df by popularity\n",
    "df = df.sort_values(\"popularity\", ascending=True)\n",
    "\n",
    "# Remove duplicate track titles, keeps row with highest pop value\n",
    "df = df[df.duplicated('name', keep=\"first\") == False]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x4rJDt9mchgx"
   },
   "source": [
    "# **Basic Exploration** <a class=\"anchor\" id=\"basicEx\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PeRD9YwlCCJs"
   },
   "source": [
    "After cleaning, we start do perform basic exploratory data analysis on the numerical and categorical data. From there, we get a rough understanding of the overall distribution and allows us to continue with more advanced data cleaning and feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qk26zb5-dXQH"
   },
   "outputs": [],
   "source": [
    "# split columns into categorical and numerical data types\n",
    "categorical = [\"artist\",'genre']\n",
    "numerical = ['danceability', 'energy', 'key', 'loudness', 'mode', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo', 'duration_ms','popularity']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j3-e_8eKdtq2"
   },
   "source": [
    "## **Numerical Data** <a class=\"anchor\" id=\"numerical1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6AREk0CutfC2"
   },
   "outputs": [],
   "source": [
    "# Plot box-plot, histogram and violin plot for all the numerical data\n",
    "def plot_numericals(dataframe):\n",
    "  f, axes = plt.subplots(len(numerical), 3, figsize=(20, 13), constrained_layout = True)\n",
    "  for i,num in enumerate(tqdm(numerical)):\n",
    "    data = pd.DataFrame(dataframe[num])\n",
    "    sb.boxplot(data = data, orient = \"h\", ax = axes[i,0],color=\"green\")\n",
    "    sb.histplot(data = data, ax = axes[i,1],color=\"blue\")\n",
    "    sb.violinplot(data = data, orient = \"h\", ax = axes[i,2],color=\"yellow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 894
    },
    "id": "qRWs-GH2dcB9",
    "outputId": "1c0591cc-8da3-4e91-dcaf-2efad9e18313"
   },
   "outputs": [],
   "source": [
    "# Check the distribution for each of the numerical values\n",
    "plot_numericals(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8T3n6Q02d_29"
   },
   "source": [
    "Observations:\n",
    "1. Most values are in range 0-1, with exception of loudness in the negative range\n",
    "2. There is a disproportionate number of tracks with 0 popularity\n",
    "3. Something amiss with instrumentalness column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GpCp9ngvgx7t"
   },
   "source": [
    "## **Categorical Data** <a class=\"anchor\" id=\"categorical1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KWj9GRf-iZ5p",
    "outputId": "23cf9600-7fdf-4863-e965-acc9f3246956"
   },
   "outputs": [],
   "source": [
    "# View the different values in artist column\n",
    "df[\"artist\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "17oePmhRi5hS"
   },
   "source": [
    "Observation: There are 16964 unique artists, the variety in artists may prove to be ineffective in training our predictive model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BRfxYsPHg40D",
    "outputId": "5ca15d4b-3831-4f29-d095-e1b45c3e069a"
   },
   "outputs": [],
   "source": [
    "# View the different values in genre column\n",
    "df[\"genre\"].value_counts()[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EXnrhrilihIz"
   },
   "source": [
    "Observation: the genres are a mix of multiple subgenres, data preprocessing required to make use of this categorical value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WEL9__CzjhFQ",
    "outputId": "27e5a98e-93fe-4fe1-e188-9a81fe8f4ae9"
   },
   "outputs": [],
   "source": [
    "# Find the number of unique genre values\n",
    "df[\"genre\"].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sPS5FpEWCtXl"
   },
   "source": [
    "Each song can be tagged with multiple genres. Our team decided to reduce the dimensionality of genres by collating the most frequently occuring genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L2DFEmVdqXOU"
   },
   "outputs": [],
   "source": [
    "# Split the combined genres into their individual categories\n",
    "dfcpy=df[\"genre\"].str.split(r\"/\", expand=True)\n",
    "# Concat all genre instances into 1 dataframe to track their frequency\n",
    "test = pd.DataFrame(pd.concat([pd.DataFrame(dfcpy[i]).value_counts() for i in range(18)],axis=0),columns=[\"freq\"]).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rBbOwnJVxRdY"
   },
   "outputs": [],
   "source": [
    "# Sort by frequency and get the most frequent genres\n",
    "test=test.sort_values(\"freq\",ascending=False)\n",
    "test.columns=[\"genre\",'freq']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oF-hPyi51yuk"
   },
   "outputs": [],
   "source": [
    "test=test.groupby(by=[\"genre\"]).sum().sort_values(\"freq\",ascending=False)\n",
    "genres = test.index.tolist()[:25]\n",
    "genres.reverse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gH74HN8YYbrA",
    "outputId": "416aa7ff-9e16-4aff-ea23-bf8e9f2b2e86"
   },
   "outputs": [],
   "source": [
    "genres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g_mHd5YC2_Hm"
   },
   "source": [
    "We now have a list of the top 25 most frequent genres (least to most frequent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bP0ScZ1YfTiR"
   },
   "source": [
    "# **Advanced Cleaning** <a class=\"anchor\" id=\"advancedCleaning\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K6R76-FZl5eJ"
   },
   "source": [
    "## **Numerical Data** <a class=\"anchor\" id=\"numerical2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9FQgaPMy3ejH"
   },
   "source": [
    "Looking at the primary EDA, we decide to normalize the data so everything is represented on a scale of 0-1. We also decided to remove songs with 0 popularity because there is a disproportionate amount of them, and they are songs which have minimal plays on spotify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XSYxluoxgKMI"
   },
   "outputs": [],
   "source": [
    "# Create a copy\n",
    "df_clean = df.copy()\n",
    "# Remove tracks with 0 popularity\n",
    "df_clean = df_clean[df_clean[\"popularity\"]>0]\n",
    "#df_clean['popularity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bLD4oxtsSjyl"
   },
   "outputs": [],
   "source": [
    "# Normalize the data using min-max so each numerical value is between 0-1\n",
    "def normalize(dataframe):\n",
    "  dataframe[numerical] = (dataframe[numerical] - dataframe[numerical].min()) / (dataframe[numerical].max() - dataframe[numerical].min())\n",
    "normalize(df_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "keJfwtENlMQ6",
    "outputId": "76cfd21f-3f8e-489e-de9e-eb704fa28233"
   },
   "outputs": [],
   "source": [
    "df_clean[\"instrumentalness\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UvtDyT0mkl7l",
    "outputId": "b88500b9-101d-4473-8063-c57ba71d3d02"
   },
   "outputs": [],
   "source": [
    "# Instrumentalness column is positively skewed, so perform squareroot transformation\n",
    "df_clean[\"instrumentalness\"] = np.sqrt(df_clean[\"instrumentalness\"])\n",
    "df_clean['popularity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 894
    },
    "id": "mlLiBVu6u0hj",
    "outputId": "f758e77b-6a08-48dc-d185-5337442fa962"
   },
   "outputs": [],
   "source": [
    "plot_numericals(df_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wRjcoM_bmCUv"
   },
   "source": [
    "## **Categorical Data** <a class=\"anchor\" id=\"categorical2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sLA14UF84GLD"
   },
   "source": [
    "Based on our previous genre EDA, we clean out NA values in genre, and filter all tracks that are part of the top 25 most frequent genres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A7r_swAb-eYy"
   },
   "outputs": [],
   "source": [
    "# Fill NA values as \"no genre\"\n",
    "df_clean['genre'] = df_clean['genre'].fillna('no genre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Cpe6MXBLRscb",
    "outputId": "dc03235f-2f30-4d28-9566-9c1b36de5e8d"
   },
   "outputs": [],
   "source": [
    "# Simplify genres and add them as an individual column\n",
    "\n",
    "for genre in genres:\n",
    "  df_clean[\"genre\"][df_clean['genre'].str.contains(genre, case=True, na=False)] = genre.upper()\n",
    "genres = [genre.upper() for genre in genres]\n",
    "df_clean = df_clean.loc[df_clean['genre'].isin(genres)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-ZBRGgIuYRRA",
    "outputId": "152bc8bb-69e9-42cf-e8cc-4c7a2de453c2"
   },
   "outputs": [],
   "source": [
    "df_clean[\"genre\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eR8M7Obmrwl7"
   },
   "source": [
    "# **Advanced Analysis** <a class=\"anchor\" id=\"advancedEx\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iOk7qz2MD-lW"
   },
   "source": [
    "After cleaning our data, we can perform exploratory data analysis to find any correlations in our data. For this project, we wish to train a model to predict whether a song will be popular or not, hence we decided to convert the numerical popularity label into binary \"pop\" and \"not pop\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5kcXMqPwZr6Q",
    "outputId": "414fdbe8-85fa-4f65-b8d8-79120f7f5797"
   },
   "outputs": [],
   "source": [
    "df_pop = df_clean.copy()\n",
    "\n",
    "names = [\"Not pop\", \"pop\"]\n",
    "df_pop['pop'] = pd.qcut(df_pop['popularity'],\n",
    "                              q=[0, .9, 1],\n",
    "                              labels=names)\n",
    "df_pop.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kReEBAXix2jL"
   },
   "source": [
    "## Graph plots <a class=\"anchor\" id=\"graphs\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iPoxP6nwESEp"
   },
   "source": [
    "Plot a heatmap to check linear correlations between labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "3_FHffmrVhYK",
    "outputId": "66d9c111-3580-400d-dbbe-ed8f4c5702c8"
   },
   "outputs": [],
   "source": [
    "# Find correlation coefficient between numerical values and popularity\n",
    "def plot_heatmap(dataframe):\n",
    "  f = plt.figure(figsize=(12, 8))\n",
    "  sb.heatmap(dataframe[numerical].corr(), vmin = -1, vmax = 1, annot = True, fmt = \".2f\")\n",
    "plot_heatmap(df_pop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iX5zzrzT_Vtg"
   },
   "source": [
    "At a glance, there ae high correlations between loudness, energy and acousticness. However, popularity does not seem to have high linear correlations with any of the labels. The highest correlation observed is -0.14 between popularity and instrumentalness and is considered a weak correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DNOTslAeFij8"
   },
   "source": [
    "Next, we plot boxplots of the labels to explore the categorical relationship with popualarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "ZCCkYrLKlGSc",
    "outputId": "d95448ae-e669-4416-d834-33675706ee77"
   },
   "outputs": [],
   "source": [
    "def plot_boxplot(dataframe, metric=\"pop\"):\n",
    "\n",
    "  for i, num in enumerate(numerical):\n",
    "    f = plt.figure(figsize=(12, 3))\n",
    "    sb.boxplot(x = num, y = metric, data = dataframe, orient = \"h\")\n",
    "\n",
    "plot_boxplot(df_pop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rqFr2EUtnXjw"
   },
   "source": [
    "We observed that most of the labels do not provide clear distinction between them and the song's popularity. This leads us to the hypothesis that multiple variables are needed to determine a song's popularity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fiIX7V5YGitq"
   },
   "source": [
    "To get a better visualization, we used a pairplot to check the distribution of popular and unpopular songs with reference to their individual labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "aWeSGaewXctf",
    "outputId": "4a459291-f483-4917-d9e6-f8c398fab292"
   },
   "outputs": [],
   "source": [
    "sb.pairplot(data = df_pop,hue=\"pop\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j23JPSRhHm0k"
   },
   "source": [
    "Overall, there does not seem to be a clear distinction between popularity and any one variable. But labels such as duration and loudness suggest that popular songs vary less compared to their unpopular counterparts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tfiEiu6-HD1n"
   },
   "source": [
    "Another visualization we did was to plot the top generes with reference to the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "6-u-ce56bEWD",
    "outputId": "febd1839-f79c-4db1-ec68-5953ec4ea3fa"
   },
   "outputs": [],
   "source": [
    "sb.pairplot(data = df_pop,hue=\"genre\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T3vViTCaHNl4"
   },
   "source": [
    "The lack of distinct pattern in the above pairplot suggests that the genre of a song is not dependant on any one variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gO3xTQ_9yIUv"
   },
   "source": [
    "## Feature Selection <a class=\"anchor\" id=\"feature\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c-Raux0WyMbj"
   },
   "source": [
    "Using our domain specific knowledge of songs, we dropped uneccesary labels mode and key as they do not affect how people hear the song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rV4BUUWD3P-_"
   },
   "outputs": [],
   "source": [
    "numericals=['danceability', 'energy', 'loudness',  'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo', 'duration_ms']\n",
    "metrics = numericals + genres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mkMSwAWTijKk"
   },
   "source": [
    "## One Hot Encoding <a class=\"anchor\" id=\"ohe\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VgK1pCJDnpP_"
   },
   "source": [
    "We use one-hot encoding to convert the values in our genere column into individual binary columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hGSS6Lt2np1e",
    "outputId": "c859a490-bc70-45f8-f1f9-cb729121f3c2"
   },
   "outputs": [],
   "source": [
    "df_onehot = df_pop.copy()\n",
    "one_hot = pd.get_dummies(df_onehot[\"genre\"])\n",
    "df_onehot = df_onehot.join(one_hot)\n",
    "print(df_onehot.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 522
    },
    "id": "MAGE_XEKoymJ",
    "outputId": "87a848d2-9c79-4928-9ffe-0f00d376b4e9"
   },
   "outputs": [],
   "source": [
    "df_onehot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MuV88TA4XG5b"
   },
   "source": [
    "# **Classification Models** <a class=\"anchor\" id=\"ml\"></a>\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9lOV1WOV4tqk"
   },
   "source": [
    "## Preparing train-test splits <a class=\"anchor\" id=\"traintest\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bfaV5ELp7Txa"
   },
   "source": [
    "We import the necessary libraries and split our data randomly into train and test sets. The train sets are used to train our machine learning models, and tests sets will be used to evaluate their performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PzvWzbmEyAzr"
   },
   "outputs": [],
   "source": [
    "# Import essential models and functions from sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, balanced_accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VL9fLQucd6fM"
   },
   "outputs": [],
   "source": [
    "# Extract Response and Predictors\n",
    "\n",
    "y = pd.DataFrame(df_onehot[\"pop\"])\n",
    "X = pd.DataFrame(df_onehot[metrics])\n",
    "\n",
    "# Split the Dataset into Train and Test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Wkp6My-xZD4"
   },
   "source": [
    "## 1. Decision Tree <a class=\"anchor\" id=\"dectree\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0-GW2LN847g7"
   },
   "source": [
    "We first explored using a simple decision tree model to classify our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 425
    },
    "id": "-TFXIQOVt3is",
    "outputId": "01481528-4108-4e1b-d395-d3de16700418"
   },
   "outputs": [],
   "source": [
    "# Decision Tree using Train Data\n",
    "dectree = DecisionTreeClassifier(max_leaf_nodes=30,max_depth=15, class_weight=\"balanced\",min_samples_split=900)  # create the decision tree object\n",
    "dectree.fit(X_train, y_train)                    # train the decision tree model\n",
    "\n",
    "# Predict Response corresponding to Predictors\n",
    "y_train_pred = dectree.predict(X_train)\n",
    "y_test_pred = dectree.predict(X_test)\n",
    "balanced_score  = balanced_accuracy_score(y_test, y_test_pred)\n",
    "print(balanced_score)\n",
    "# Check the Goodness of Fit (on Train Data)\n",
    "print(\"Goodness of Fit of Model \\tTrain Dataset\")\n",
    "print(\"Classification Accuracy \\t:\", dectree.score(X_train, y_train))\n",
    "print()\n",
    "\n",
    "# Check the Goodness of Fit (on Test Data)\n",
    "print(\"Goodness of Fit of Model \\tTest Dataset\")\n",
    "print(\"Classification Accuracy \\t:\", dectree.score(X_test, y_test))\n",
    "print()\n",
    "\n",
    "# Plot the Confusion Matrix for Train and Test\n",
    "f, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "sb.heatmap(confusion_matrix(y_train, y_train_pred),\n",
    "           annot = True, fmt=\".0f\", annot_kws={\"size\": 18}, ax = axes[0])\n",
    "results = confusion_matrix(y_test, y_test_pred)\n",
    "sb.heatmap(results, \n",
    "           annot = True, fmt=\".0f\", annot_kws={\"size\": 18}, ax = axes[1])\n",
    "\n",
    "tpr = results[1][1]/results[1].sum()\n",
    "tnr = results[0][0]/results[0].sum()\n",
    "print(\"True positive rate: \\t{}\".format(tpr))\n",
    "print(\"True negative rate: \\t{}\".format(tnr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Balanced accuracy score: 0.5841 (to 4dp)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AQWq19f95NCB"
   },
   "source": [
    "Although this model provided a decent true positive rate, the low true negative rate makes it impractical and suggests overfitting on popular songs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KlFSEyuZ51sm"
   },
   "source": [
    "We make use of grid search to tune our hyperparameters for the decision tree. Limiting these parameters prevent our tree from overfitting, and allows our model to have higher accuracy on the test data. The parameters we have chosen are:\n",
    "1. max_depth - limits the maximum depth that the tree can go\n",
    "2. max_leaf_nodes - limits the number of leaf nodes the tree can have\n",
    "3. min_sample_split - requires a branch to have a certain number of samples before splitting is allowed\n",
    "4. max_features - restricts the number of features to be considered for splitting\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "As our popular to unpopular song ratio is imbalanced, we switched to a different scoring metric to evaluate the model's performance. The usage of \"balanced accuracy\" adjusts the class weights in proportion to their frequency in the dataset, and is a alternative solution to over/under sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nKxDW2kO8b8i"
   },
   "outputs": [],
   "source": [
    "# Create a function to evaluate the performance of a grid search model\n",
    "def print_grid_report(model):\n",
    "  # print the best parameters found by gridsearch, and its score on the test set\n",
    "  print(model.best_params_)\n",
    "  y_test_pred = model.predict(X_test)\n",
    "  y_train_pred = model.predict(X_train)\n",
    "  print(\"Balanced accuracy score (test):\" , model.score(X_test, y_test))\n",
    "\n",
    "  #Plot confusion matrix for train and test data\n",
    "  f, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "  sb.heatmap(confusion_matrix(y_train, y_train_pred),\n",
    "            annot = True, fmt=\".0f\", annot_kws={\"size\": 18}, ax = axes[0])\n",
    "  results = confusion_matrix(y_test, y_test_pred)\n",
    "  sb.heatmap(results, \n",
    "            annot = True, fmt=\".0f\", annot_kws={\"size\": 18}, ax = axes[1])\n",
    "  \n",
    "  #Calculate true and false positive rates\n",
    "  results = confusion_matrix(y_test, y_test_pred)\n",
    "  tpr = results[1][1]/results[1].sum()\n",
    "  tnr = results[0][0]/results[0].sum()\n",
    "  print(\"True positive rate: \\t{}\".format(tpr))\n",
    "  print(\"True negative rate: \\t{}\".format(tnr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 354
    },
    "id": "hfXlCFJAFd-K",
    "outputId": "e37f10a0-22fb-41b4-8cd5-d4e21aaaea3c"
   },
   "outputs": [],
   "source": [
    "# Find the best parameter range to use\n",
    "parameters = {\"max_depth\": [None,10,20,30,40,50], \"max_leaf_nodes\": [None,10,20,30,40,50], \"class_weight\":[\"balanced\"], \"min_samples_split\":[2,50,500,1000,1500],\n",
    "              \"criterion\":[\"gini\", \"entropy\"],\"max_features\":[None,\"sqrt\", \"log2\"]}\n",
    "grid = GridSearchCV(DecisionTreeClassifier(), parameters, refit = True, verbose = 3,n_jobs=-1,scoring=\"balanced_accuracy\")\n",
    "grid.fit(X_train, y_train)\n",
    " \n",
    "print_grid_report(grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Balanced accuracy score (after fine tuning): 0.5844 (to 4dp)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6kkEC_2y2cA4"
   },
   "source": [
    "Using grid search, we have managed to reduce the number of false positives predicted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yrXtwR7g9SZp"
   },
   "source": [
    "However, the overall balanced score for the decision tree model is relatively low(0.577), and cannot be considered reliable in predicting popular songs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cw7AojHvxiRf"
   },
   "source": [
    "## 2. Random Forest <a class=\"anchor\" id=\"randomForest\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0Ne1iNIQ_KnO"
   },
   "source": [
    "The next alternative we try is the random forest classifier. Random forest  fits a number of decision tree classifiers on various sub-samples of the dataset and uses averaging to improve the predictive accuracy and control over-fitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 408
    },
    "id": "1yWI7VoqowdU",
    "outputId": "b687bff7-b091-4f3f-8f1d-2fac7a37c1ab"
   },
   "outputs": [],
   "source": [
    "# Decision Tree using Train Data\n",
    "dectree = RandomForestClassifier(max_depth=30, max_leaf_nodes=30, class_weight=\"balanced\",n_estimators=400)  # create the decision tree object\n",
    "dectree.fit(X_train, y_train.values.ravel())                    # train the decision tree model\n",
    "\n",
    "# Predict Response corresponding to Predictors\n",
    "y_train_pred = dectree.predict(X_train)\n",
    "y_test_pred = dectree.predict(X_test)\n",
    "\n",
    "results = confusion_matrix(y_test, y_test_pred)\n",
    "tpr = results[1][1]/results[1].sum()\n",
    "tnr = results[0][0]/results[0].sum()\n",
    "print(tnr, tpr)\n",
    "\n",
    "# Plot the Confusion Matrix for Train and Test\n",
    "f, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "sb.heatmap(confusion_matrix(y_train, y_train_pred),\n",
    "           annot = True, fmt=\".0f\", annot_kws={\"size\": 18}, ax = axes[0])\n",
    "\n",
    "sb.heatmap(results, \n",
    "           annot = True, fmt=\".0f\", annot_kws={\"size\": 18}, ax = axes[1])\n",
    "\n",
    "\n",
    "# Check the Goodness of Fit (on Train Data)\n",
    "print(\"Goodness of Fit of Model \\tTrain Dataset\")\n",
    "print(\"Classification Accuracy \\t:\", dectree.score(X_train, y_train))\n",
    "print()\n",
    "\n",
    "# Check the Goodness of Fit (on Test Data)\n",
    "print(\"Goodness of Fit of Model \\tTest Dataset\")\n",
    "print(\"Classification Accuracy \\t:\", dectree.score(X_test, y_test))\n",
    "\n",
    "print(\"True positive rate: \\t{}\".format(tpr))\n",
    "print(\"True negative rate: \\t{}\".format(tnr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o5NK8hTknIdQ"
   },
   "source": [
    "Similar to our decision tree, we run grid search to find the best parameters for the random forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "id": "rNEpdsv7DfsQ",
    "outputId": "e2d31ea7-9acf-4a1c-d6b3-97d4da3d4425"
   },
   "outputs": [],
   "source": [
    "# Find the general best parameters \n",
    "parameters = {\"max_depth\": [10,20,30,40], \"max_leaf_nodes\": [30,40,50,60], \"class_weight\":[\"balanced\"], \"min_samples_split\":[2],\n",
    "              \"criterion\":[\"gini\"],\"max_features\":[\"sqrt\"], \"n_estimators\":[400]}\n",
    "grid = GridSearchCV(RandomForestClassifier(), parameters, refit = True, verbose = 3,n_jobs=-1, scoring='balanced_accuracy')\n",
    "grid.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "print_grid_report(grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Balanced accuracy score (after fine tuning): 0.6094 (to 4dp)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ta2RI4XBjtNO"
   },
   "source": [
    "## 3. K nearest neighbours <a class=\"anchor\" id=\"knn\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 713
    },
    "id": "-U1nh4_6UAM8",
    "outputId": "47d6c50b-a026-4eb9-acaa-7d7907185eed"
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Decision Tree using Train Data\n",
    "classifier = KNeighborsClassifier()\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict Response corresponding to Predictors\n",
    "y_train_pred = classifier.predict(X_train)\n",
    "y_test_pred = classifier.predict(X_test)\n",
    "\n",
    "# Grid search\n",
    "parameters = {\"n_neighbors\": [10,20,30,40,50], \"weights\":[\"uniform\", \"distance\"], \"leaf_size\":[30,40,50,60],\n",
    "              \"p\":[1, 2]}\n",
    "grid = GridSearchCV(KNeighborsClassifier(), parameters, refit = True, verbose = 3, n_jobs=-1, scoring='balanced_accuracy')\n",
    "grid.fit(X_train, y_train.values.ravel())\n",
    " \n",
    "# print best parameter after tuning\n",
    "print(grid.best_params_)\n",
    "grid_predictions = grid.predict(X_test)\n",
    "\n",
    "   \n",
    "# print classification report \n",
    "print(classification_report(y_test, grid_predictions))\n",
    "\n",
    "accuracy = balanced_accuracy_score(y_test, grid_predictions)\n",
    "print(accuracy)\n",
    "\n",
    "# Check the Goodness of Fit (on Train Data)\n",
    "print(\"Goodness of Fit of Model \\tTrain Dataset\")\n",
    "print(\"Classification Accuracy \\t:\", grid.score(X_train, y_train))\n",
    "print()\n",
    "\n",
    "# Check the Goodness of Fit (on Test Data)\n",
    "print(\"Goodness of Fit of Model \\tTest Dataset\")\n",
    "print(\"Classification Accuracy \\t:\", grid.score(X_test, y_test))\n",
    "print()\n",
    "\n",
    "# Plot the Confusion Matrix for Train and Test\n",
    "f, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "sb.heatmap(confusion_matrix(y_train, y_train_pred),\n",
    "           annot = True, fmt=\".0f\", annot_kws={\"size\": 18}, ax = axes[0])\n",
    "\n",
    "results = confusion_matrix(y_test, grid_predictions)\n",
    "sb.heatmap(results, \n",
    "           annot = True, fmt=\".0f\", annot_kws={\"size\": 18}, ax = axes[1])\n",
    "\n",
    "tpr = results[1][1]/results[1].sum()\n",
    "tnr = results[0][0]/results[0].sum()\n",
    "print(\"True positive rate: \\t{}\".format(tpr))\n",
    "print(\"True negative rate: \\t{}\".format(tnr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Balanced accuracy score: 0.5027 (to 4dp)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 410
    },
    "id": "2mlHdExIf-ZK",
    "outputId": "50e2c8b4-ff71-4fd8-b277-0c36cdcabe31"
   },
   "outputs": [],
   "source": [
    "# Fine-tune the parameters for the best performance\n",
    "parameters = {\"n_neighbors\": [i for i in range(5,15)], \"weights\":[\"distance\"], \"leaf_size\":[30],\n",
    "              \"p\":[2]}\n",
    "grid = GridSearchCV(KNeighborsClassifier(), parameters, refit = True, verbose = 3,n_jobs=-1,scoring=\"balanced_accuracy\")\n",
    "grid.fit(X_train, y_train)\n",
    " \n",
    "print_grid_report(grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Balanced accuracy score (after fine tuning): 0.5127 (to 4dp)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XbdUYnY3tJhi"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kvRaK7sTtKG-"
   },
   "source": [
    "## 4. Logistic regression <a class=\"anchor\" id=\"logreg\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 856
    },
    "id": "axyRJEdwtNP3",
    "outputId": "8871493c-e015-4f90-d7a7-c8ef6809eb23"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Decision Tree using Train Data\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train,y_train)\n",
    "\n",
    "# Predict Response corresponding to Predictors\n",
    "y_train_pred = logreg.predict(X_train)\n",
    "y_test_pred = logreg.predict(X_test)\n",
    "\n",
    "# Grid search\n",
    "parameters = {\"solver\":[\"sag\", \"saga\"], \"class_weight\":[\"balanced\"], \"max_iter\":[20,40,60,80,100],\n",
    "              \"n_jobs\":[-1]}\n",
    "grid = GridSearchCV(LogisticRegression(), parameters, refit = True, verbose = 3, n_jobs=-1, scoring='balanced_accuracy')\n",
    "grid.fit(X_train, y_train.values.ravel())\n",
    "\n",
    " \n",
    "# print best parameter after tuning \n",
    "print(grid.best_params_) \n",
    "grid_predictions = grid.predict(X_test) \n",
    "\n",
    "   \n",
    "# print classification report \n",
    "print(classification_report(y_test, grid_predictions))\n",
    "\n",
    "accuracy = balanced_accuracy_score(y_test, grid_predictions)\n",
    "print(accuracy)\n",
    "\n",
    "# Check the Goodness of Fit (on Train Data)\n",
    "print(\"Goodness of Fit of Model \\tTrain Dataset\")\n",
    "print(\"Classification Accuracy \\t:\", grid.score(X_train, y_train))\n",
    "print()\n",
    "\n",
    "# Check the Goodness of Fit (on Test Data)\n",
    "print(\"Goodness of Fit of Model \\tTest Dataset\")\n",
    "print(\"Classification Accuracy \\t:\", grid.score(X_test, y_test))\n",
    "print()\n",
    "\n",
    "# Plot the Confusion Matrix for Train and Test\n",
    "f, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "sb.heatmap(confusion_matrix(y_train, y_train_pred),\n",
    "           annot = True, fmt=\".0f\", annot_kws={\"size\": 18}, ax = axes[0])\n",
    "\n",
    "results = confusion_matrix(y_test, grid_predictions)\n",
    "sb.heatmap(results, \n",
    "           annot = True, fmt=\".0f\", annot_kws={\"size\": 18}, ax = axes[1])\n",
    "\n",
    "tpr = results[1][1]/results[1].sum()\n",
    "tnr = results[0][0]/results[0].sum()\n",
    "print(\"True positive rate: \\t{}\".format(tpr))\n",
    "print(\"True negative rate: \\t{}\".format(tnr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Balanced accuracy score: 0.5964 (to 4dp)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 445
    },
    "id": "408L-FH2hG--",
    "outputId": "53ed6b3d-3b86-4555-fd60-800722e7c05f"
   },
   "outputs": [],
   "source": [
    "# Fine-tune the parameters for the best performance\n",
    "parameters = {\"solver\": [\"sag\"], \"class_weight\": [\"balanced\"], \"max_iter\":[i for i in range(50,70)], \"n_jobs\":[-1]}\n",
    "grid = GridSearchCV(LogisticRegression(), parameters, refit = True, verbose = 3,n_jobs=-1,scoring=\"balanced_accuracy\")\n",
    "grid.fit(X_train, y_train)\n",
    " \n",
    "print_grid_report(grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Balanced accuracy score (after fine tuning): 0.5958 (to 4dp)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression, although has a balanced accuracy score close to that of Random forest, it is still lower. Therefore we will not select this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ol4hK5rA9BWW"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J7Db-tJN9BjP"
   },
   "source": [
    "## 5. Gradient boosting <a class=\"anchor\" id=\"gradientBoosting\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 622
    },
    "id": "e1K5wfWf9IoQ",
    "outputId": "54e9afbf-ec0b-48d1-aa22-d42f45217e66"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Scale the data\n",
    "scaler = MinMaxScaler()\n",
    "X_train_transformed = scaler.fit_transform(X_train)\n",
    "X_test_transformed = scaler.transform(X_test)\n",
    "\n",
    "# Decision Tree using Train Data\n",
    "gbc = GradientBoostingClassifier()\n",
    "gbc.fit(X_train_transformed,y_train)\n",
    "\n",
    "# Predict Response corresponding to Predictors\n",
    "y_train_pred = gbc.predict(X_train_transformed)\n",
    "y_test_pred = gbc.predict(X_test_transformed)\n",
    "\n",
    "# Grid search\n",
    "parameters = {\"n_estimators\":[20,40,60,80,100], \"learning_rate\":[0.05, 0.075, 0.1, 0.25, 0.5, 0.75, 1], \"max_depth\":[2,3,5],\n",
    "              \"min_samples_split\":[100], \"min_samples_leaf\":[30], \"max_features\":[\"sqrt\"]}\n",
    "grid = GridSearchCV(GradientBoostingClassifier(), parameters, refit = True, verbose = 3, n_jobs=-1, scoring='balanced_accuracy')\n",
    "grid.fit(X_train_transformed, y_train.values.ravel())\n",
    "\n",
    " \n",
    "# print best parameter after tuning \n",
    "print(grid.best_params_)\n",
    "grid_predictions = grid.predict(X_test_transformed)\n",
    "\n",
    "   \n",
    "# print classification report \n",
    "print(classification_report(y_test, grid_predictions))\n",
    "\n",
    "accuracy = balanced_accuracy_score(y_test, grid_predictions)\n",
    "print(accuracy)\n",
    "\n",
    "# Check the Goodness of Fit (on Train Data)\n",
    "print(\"Goodness of Fit of Model \\tTrain Dataset\")\n",
    "print(\"Classification Accuracy \\t:\", grid.score(X_train_transformed, y_train))\n",
    "print()\n",
    "\n",
    "# Check the Goodness of Fit (on Test Data)\n",
    "print(\"Goodness of Fit of Model \\tTest Dataset\")\n",
    "print(\"Classification Accuracy \\t:\", grid.score(X_test_transformed, y_test))\n",
    "print()\n",
    "\n",
    "# Plot the Confusion Matrix for Train and Test\n",
    "f, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "sb.heatmap(confusion_matrix(y_train, y_train_pred),\n",
    "           annot = True, fmt=\".0f\", annot_kws={\"size\": 18}, ax = axes[0])\n",
    "\n",
    "results = confusion_matrix(y_test, grid_predictions)\n",
    "sb.heatmap(results, \n",
    "           annot = True, fmt=\".0f\", annot_kws={\"size\": 18}, ax = axes[1])\n",
    "\n",
    "tpr = results[1][1]/results[1].sum()\n",
    "tnr = results[0][0]/results[0].sum()\n",
    "print(\"True positive rate: \\t{}\".format(tpr))\n",
    "print(\"True negative rate: \\t{}\".format(tnr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Balanced accuracy score: 0.5210 (to 4dp)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient boosting classifier model does not yield the highest balanced accuracy score amongst the previous models, and will hence not be selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6a9vTzyAwUgZ"
   },
   "outputs": [],
   "source": [
    "# Fine-tune the parameters(max_depth + min_samples_split) for the best performance\n",
    "parameters = {\"n_estimators\":[80], \"learning_rate\":[0.05, 0.075, 0.1, 0.25, 0.5, 0.75, 1], \"max_depth\":[i for i in range(5,15,2)],\n",
    "              \"min_samples_split\":[j for j in range(100,500,100)], \"min_samples_leaf\":[30], \"max_features\":[\"sqrt\"]}\n",
    "grid = GridSearchCV(GradientBoostingClassifier(), parameters, refit = True, verbose = 3,n_jobs=-1,scoring=\"balanced_accuracy\")\n",
    "grid.fit(X_train_transformed, y_train.values.ravel())\n",
    " \n",
    "print_grid_report(grid)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "4aYUC4slYgZR",
    "YRj6jCbwbvvh"
   ],
   "name": "SC1015.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
